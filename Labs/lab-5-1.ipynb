{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Lab 5.1: Implementing Information Extraction\n", "\n", "In this lab, you will use Amazon Comprehend to extract key entity and event information from financial documents.\n", "\n", "## About this dataset\n", "\n", "The [sample_finance_dataset.txt](https://github.com/aws-samples/amazon-comprehend-examples/tree/master/amazon_comprehend_events_tutorial) file contains a set of 118 press releases in doclines format from the [Amazon press release archive](https://press.aboutamazon.com/press-releases).\n", "\n", "## Lab steps\n", "\n", "To complete this lab, you will follow these steps:\n", "\n", "1. [Installing the packages](#1.-Install-packages)\n", "2. [Writing the documents to Amazon S3](#2.-Write-documents-to-S3)\n", "3. [Starting an asynchronous events detection job using the SDK](#3.-Start-an-asynchronous-events-detection-job-using-the-SDK)\n", "4. [Analyzing the Amazon Comprehend Events output](#4.-Analyzing-Comprehend-Events-output)\n", "\n", "\n", "## Submitting your work\n", "\n", "1. In the lab console, choose **Submit** to record your progress and when prompted, choose **Yes**.\n", "\n", "1. If the results don't display after a couple of minutes, return to the top of these instructions and choose **Grades**.\n", "\n", "     **Tip:** You can submit your work multiple times. After you change your work, choose **Submit** again. Your last submission is what will be recorded for this lab.\n", "\n", "1. To find detailed feedback on your work, choose **Details** followed by **View Submission Report**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Installing packages\n", "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))\n", "\n", "Start by updating and installing the packages that you will use in the notebook. \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install smart_open\n", "!pip install networkx\n", "!pip install pandas\n", "!pip install pyvis\n", "!pip install spacy\n", "!pip install ipywidgets"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  \n", "\n", "__Note:__ Before you proceed with this lab for the first time, we recommend that you restart the kernel by choosing __Kernel__ > __Restart Kernel__."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["%matplotlib inline\n", "\n", "import json\n", "import requests\n", "import uuid\n", "\n", "import networkx as nx\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import boto3\n", "import smart_open\n", "\n", "from time import sleep\n", "from matplotlib import cm, colors\n", "from spacy import displacy\n", "from collections import Counter\n", "from pyvis.network import Network"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Writing the documents to Amazon S3\n", "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))\n", "\n", "The data folder for this lab has a text file containing Amazon press releases as example documents. They have been saved in a single file with one document per line.\n", "\n", "In this section, you will upload the sample_finance_dataset.txt file to an Amazon Simple Storage Service (Amazon S3) bucket for processing. The processing output will be returned to the same bucket."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bucket = \"c51302a798363l1767466t1w753256443787-labbucket-vzr6xg8irt81\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Client and session information\n", "session = boto3.Session()\n", "s3_client = session.client(service_name=\"s3\")\n", "\n", "# Constants for S3 bucket and input data file\n", "\n", "filename = \"sample_finance_dataset.txt\"\n", "input_data_s3_path = f's3://{bucket}/' + filename\n", "output_data_s3_path = f's3://{bucket}/'\n", "\n", "# Upload the local file to S3\n", "s3_client.upload_file(\"../s3/\" + filename, bucket, filename)\n", "\n", "# Load the documents locally for later analysis\n", "with open(\"../s3/\" + filename, \"r\") as fi:\n", "    raw_texts = [line.strip() for line in fi.readlines()]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Starting an asynchronous events detection job using the SDK\n", "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))\n", "\n", "In this section, you will start the events detection job. You will use the `start_events_detection_job` function. \n", "\n", "Note that the API requires an AWS Identity and Access Management (IAM) role with List, Read, and Write permissions for the S3 bucket that you specified in the previous section."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Amazon Comprehend client information\n", "comprehend_client = session.client(service_name=\"comprehend\")\n", "\n", "# IAM role with access to Amazon Comprehend and the specified S3 bucket\n", "job_data_access_role = 'arn:aws:iam::753256443787:role/service-role/c51302a798363l1767466t1w7-ComprehendDataAccessRole-396LD2R02VHP'\n", "\n", "# Other job parameters\n", "input_data_format = 'ONE_DOC_PER_LINE'\n", "job_uuid = uuid.uuid1()\n", "job_name = f\"events-job-{job_uuid}\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Because you are processing company press releases, you can define the event types that you are most interested in. For the full list of event types, see the [Amazon Comprehend Developer Guide](https://docs.aws.amazon.com/comprehend/latest/dg/how-events.html#events-types)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["event_types = [\"BANKRUPTCY\", \"EMPLOYMENT\", \"CORPORATE_ACQUISITION\", \n", "               \"INVESTMENT_GENERAL\", \"CORPORATE_MERGER\", \"IPO\",\n", "               \"RIGHTS_ISSUE\", \"SECONDARY_OFFERING\", \"SHELF_OFFERING\",\n", "               \"TENDER_OFFERING\", \"STOCK_SPLIT\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Start the Amazon Comprehend job."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Begin the inference job\n", "response = comprehend_client.start_events_detection_job(\n", "    InputDataConfig={'S3Uri': input_data_s3_path,\n", "                     'InputFormat': input_data_format},\n", "    OutputDataConfig={'S3Uri': output_data_s3_path},\n", "    DataAccessRoleArn=job_data_access_role,\n", "    JobName=job_name,\n", "    LanguageCode='en',\n", "    TargetEventTypes=event_types\n", ")\n", "\n", "# Get the job ID\n", "events_job_id = response['JobId']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get the current job status\n", "job = comprehend_client.describe_events_detection_job(JobId=events_job_id)\n", "\n", "# Loop until the job is completed\n", "waited = 0\n", "timeout_minutes = 30\n", "while job['EventsDetectionJobProperties']['JobStatus'] != 'COMPLETED':\n", "    sleep(60)\n", "    waited += 60\n", "    assert waited//60 < timeout_minutes, \"Job timed out after %d seconds.\" % waited\n", "    print('.', end='')\n", "    job = comprehend_client.describe_events_detection_job(JobId=events_job_id)\n", "\n", "print('Ready')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When the job is complete, download the results in memory."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# The output filename is the input filename + \".out\"\n", "output_data_s3_file = job['EventsDetectionJobProperties']['OutputDataConfig']['S3Uri'] + filename + '.out'\n", "\n", "# Load the output into a results dictionary\n", "results = []\n", "with smart_open.open(output_data_s3_file) as fi:\n", "    results.extend([json.loads(line) for line in fi.readlines() if line])"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## 4. Analyzing the Amazon Comprehend Events output\n", "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))\n", "\n", "With the data downloaded, it's time to analyze the results.\n", "\n", "You will use the first document in the submitted dataset as an example. The document is typical of what a financial document might consume when projecting market trends. For the full press release, see [Amazon.com Announces Third Quarter Sales up 34% to $43.7 Billion](https://press.aboutamazon.com/news-releases/news-release-details/amazoncom-announces-third-quarter-sales-34-437-billion).\n", "\n", "The following provides the text of the press release:"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["> Amazon.com, Inc. (NASDAQ: AMZN) today announced financial results for its third quarter ended September 30, 2017.\n", "\n", "> Operating cash flow increased 14% to \\\\$17.1 billion for the trailing twelve months, compared with \\\\$15.0 billion for the trailing twelve months ended September 30, 2016. Free cash flow decreased to \\\\$8.1 billion for the trailing twelve months, compared with \\\\$9.0 billion for the trailing twelve months ended September 30, 2016. Free cash flow less lease principal repayments decreased to \\\\$3.5 billion for the trailing twelve months, compared with \\\\$5.3 billion for the trailing twelve months ended September 30, 2016. Free cash flow less finance lease principal repayments and assets acquired under capital leases decreased to an outflow of \\\\$1.0 billion for the trailing twelve months, compared with an inflow of \\\\$3.8 billion for the trailing twelve months ended September 30, 2016.\n", "\n", "> Common shares outstanding plus shares underlying stock-based awards totaled 503 million on September 30, 2017, compared with 496 million one year ago.\n", "\n", "> Net sales increased 34% to \\\\$43.7 billion in the third quarter, compared with \\\\$32.7 billion in third quarter 2016. Net sales includes \\\\$1.3 billion from Whole Foods Market, which Amazon acquired on August 28, 2017. Excluding Whole Foods Market and the \\\\$124 million favorable impact from year-over-year changes in foreign exchange rates throughout the quarter, net sales increased 29% compared with third quarter 2016.\n", "\n", "> Operating income decreased 40% to \\\\$347 million in the third quarter, compared with operating income of \\\\$575 million in third quarter 2016. Operating income includes income of \\\\$21 million from Whole Foods Market.\n", "\n", "> Net income was \\\\$256 million in the third quarter, or \\\\$0.52 per diluted share, compared with net income of \\\\$252 million, or \\\\$0.52 per diluted share, in third quarter 2016.\n", "\n", "> \u201cIn the last month alone, we\u2019ve launched five new Alexa-enabled devices, introduced Alexa in India, announced integration with BMW, surpassed 25,000 skills, integrated Alexa with Sonos speakers, taught Alexa to distinguish between two voices, and more. Because Alexa\u2019s brain is in the AWS cloud, her new abilities are available to all Echo customers, not just those who buy a new device,\u201d said Jeff Bezos, Amazon founder and CEO. \u201cAnd it\u2019s working \u2014 customers have purchased tens of millions of Alexa-enabled devices, given Echo devices over 100,000 5-star reviews, and active customers are up more than 5x since the same time last year. With thousands of developers and hardware makers building new Alexa skills and devices, the Alexa experience will continue to get even better.\u201d"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Understanding the Amazon Comprehend Events system output\n", "\n", "The system returns JSON output for each submitted document. The following cells show the structure of the response. \n", "\n", "Note:\n", "* The system output contains separate objects for `Entities` and `Events`, which are each organized into groups of coreferential object.  \n", "* Two additional fields, `File` and `Line`, are present to track document provenance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use the first results document for analysis\n", "result = results[0]\n", "raw_text = raw_texts[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["raw_text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["result"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Events are groups of triggers\n", "\n", "* The API output includes the text, character offset, and type of each trigger.\n", "\n", "* Confidence scores for classification tasks are given as `Score`. Confidence of event group membership is given as `GroupScore`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "-"}}, "outputs": [], "source": ["result['Events'][1]['Triggers']"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Arguments are linked to entities by the EntityIndex\n", "\n", "* The API also returns the classification confidence of the role assignment."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "-"}}, "outputs": [], "source": ["result['Events'][1]['Arguments']"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Entities are groups of mentions\n", "\n", "* The API output includes the text, character offset, and type of each mention.  \n", "\n", "* Confidence scores for classification tasks are given as `Score`. Confidence of entity group membership is given as `GroupScore`.  "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "-"}}, "outputs": [], "source": ["result['Entities'][0]['Mentions']"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Visualizing the events and entities\n", "\n", "In this section, you explore a number of tabulations and visualizations to help understand what the API is returning.\n", "\n", "First, you consider a visualization of spans, both triggers and entity mentions. One of the most essential visualization tasks for sequence labeling is highlighting tagged text in documents. For demo purposes, you will use [displaCy](https://spacy.io/usage/visualizers)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# Convert the output to the displaCy format\n", "entities = [\n", "    {'start': m['BeginOffset'], 'end': m['EndOffset'], 'label': m['Type']}\n", "    for e in result['Entities']\n", "    for m in e['Mentions']\n", "]\n", "\n", "triggers = [\n", "    {'start': t['BeginOffset'], 'end': t['EndOffset'], 'label': t['Type']}\n", "    for e in result['Events']\n", "    for t in e['Triggers']\n", "]\n", "\n", "# Spans need to be sorted for displaCy to process them correctly\n", "spans = sorted(entities + triggers, key=lambda x: x['start'])\n", "tags = [s['label'] for s in spans]\n", "\n", "output = [{\"text\": raw_text, \"ents\": spans, \"title\": None, \"settings\": {}}]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# Miscellaneous objects for presentation purposes\n", "spectral = cm.get_cmap(\"Spectral\", len(tags))\n", "tag_colors = [colors.rgb2hex(spectral(i)) for i in range(len(tags))]\n", "color_map = dict(zip(*(tags, tag_colors)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Note that only entities participating in events are shown\n", "displacy.render(output, style=\"ent\", options={\"colors\": color_map}, manual=True)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Rendering as tabular data\n", "\n", "A common use for Amazon Comprehend Events is to create structured data from unstructured text. For this lab, you will do this with pandas.\n", "\n", "First, flatten the hierarchical JSON data into a pandas DataFrame. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# Create the entity DataFrame. Entity indices must be explicitly created.\n", "entities_df = pd.DataFrame([\n", "    {\"EntityIndex\": i, **m}\n", "    for i, e in enumerate(result['Entities'])\n", "    for m in e['Mentions']\n", "])\n", "\n", "# Create the events DataFrame. Event indices must be explicitly created.\n", "events_df = pd.DataFrame([\n", "    {\"EventIndex\": i, **a, **t}\n", "    for i, e in enumerate(result['Events'])\n", "    for a in e['Arguments']\n", "    for t in e['Triggers']\n", "])\n", "\n", "# Join the two tables into one flat data structure\n", "events_df = events_df.merge(entities_df, on=\"EntityIndex\", suffixes=('Event', 'Entity'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "-"}}, "outputs": [], "source": ["events_df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Creating a more succinct representation\n", "\n", "Because you are primarily interested in the *event structure*, make the data more transparent by creating a new table with Roles as column headers, grouped by Event."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["def format_compact_events(x):\n", "    \"\"\"Collapse groups of mentions and triggers into a single set.\"\"\"\n", "    # Take the most commonly occurring EventType and the set of triggers\n", "    d = {\"EventType\": Counter(x['TypeEvent']).most_common()[0][0],\n", "         \"Triggers\": set(x['TextEvent'])}\n", "    # For each argument Role, collect the set of mentions in the group\n", "    for role in x['Role']:\n", "        d.update({role: set((x[x['Role']==role]['TextEntity']))})\n", "    return d\n", "\n", "# Group data by EventIndex and format\n", "event_analysis_df = pd.DataFrame(\n", "    events_df.groupby(\"EventIndex\").apply(format_compact_events).tolist()\n", ").fillna('')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "-"}}, "outputs": [], "source": ["event_analysis_df"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Graphing event semantics\n", "\n", "A semantic graph often provides the most striking representation of Amazon Comprehend Events output. A semantic graph is a network of the entities and events referenced in a document or documents.\n", "\n", "The following code uses two open-source libraries, NetworkX and pyvis, to render the system output. In the resulting graph, nodes are entity mentions and triggers, while edges are the argument roles that the entities hold in relation to the triggers."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "skip"}}, "source": ["#### Formatting the data\n", "ID Comment: Should we separate the words 'network and X' within the first sentence?\n", "System output must first be conformed to the node (i.e., vertex) and edge list format that networkx requires. This requires iterating over triggers, entities, and argument structural relations. Note that you can use the `GroupScore` and `Score` keys on various objects to prune nodes and edges in which the model has less confidence. You can also use various strategies to pick a \"canonical\" mention from each mention group to appear in the graph. For this task, you will use the mention with the string-wise longest extent."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# Entities are associated with events by group, not individual mention\n", "# For simplicity, aassume the canonical mention is the longest one\n", "def get_canonical_mention(mentions):\n", "    extents = enumerate([m['Text'] for m in mentions])\n", "    longest_name = sorted(extents, key=lambda x: len(x[1]))\n", "    return [mentions[longest_name[-1][0]]]\n", "\n", "# Set a global confidence threshold\n", "thr = 0.5\n", "\n", "# Nodes are (id, type, tag, score, mention_type) tuples\n", "trigger_nodes = [\n", "    (\"tr%d\" % i, t['Type'], t['Text'], t['Score'], \"trigger\")\n", "    for i, e in enumerate(result['Events'])\n", "    for t in e['Triggers'][:1]\n", "    if t['GroupScore'] > thr\n", "]\n", "entity_nodes = [\n", "    (\"en%d\" % i, m['Type'], m['Text'], m['Score'], \"entity\")\n", "    for i, e in enumerate(result['Entities'])\n", "    for m in get_canonical_mention(e['Mentions'])\n", "    if m['GroupScore'] > thr\n", "]\n", "\n", "# Edges are (trigger_id, node_id, role, score) tuples\n", "argument_edges = [\n", "    (\"tr%d\" % i, \"en%d\" % a['EntityIndex'], a['Role'], a['Score'])\n", "    for i, e in enumerate(result['Events'])\n", "    for a in e['Arguments']\n", "    if a['Score'] > thr\n", "]    "]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "skip"}}, "source": ["#### Creating a compact graph\n", "\n", "Once the nodes and edges are defined, you can create and visualize the graph."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["G = nx.Graph()\n", "\n", "# Iterate over triggers and entity mentions\n", "for mention_id, tag, extent, score, mtype in trigger_nodes + entity_nodes:\n", "    label = extent if mtype.startswith(\"entity\") else tag\n", "    G.add_node(mention_id, label=label, size=score*10, color=color_map[tag], tag=tag, group=mtype)\n", "    \n", "# Iterate over argument role assignments\n", "for event_id, entity_id, role, score in argument_edges:\n", "    G.add_edges_from(\n", "        [(event_id, entity_id)],\n", "        label=role,\n", "        weight=score*100,\n", "        color=\"grey\"\n", "    )\n", "\n", "# Drop mentions that don't participate in events\n", "G.remove_nodes_from(list(nx.isolates(G)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["nt = Network(\"600px\", \"800px\", notebook=True, heading=\"\")\n", "nt.from_nx(G)\n", "nt.show(\"compact_nx.html\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Creating a more complete graph\n", "\n", "The previous graph is compact, and only relays the essential event type and argument role information. You can use a slightly more complicated set of functions to graph all of the information that the API returns."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# This function in `events_graph.py` plots a complete graph of the document\n", "# The graph shows all events, triggers, entities, and their groups\n", "\n", "import events_graph as evg\n", "\n", "evg.plot(result, node_types=['event', 'trigger', 'entity_group', 'entity'], thr=0.5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Congratulations!\n", "\n", "You have completed this lab, and you can now end the lab by following the lab guide instructions."]}, {"cell_type": "markdown", "metadata": {}, "source": ["*\u00a92021 Amazon Web Services, Inc. or its affiliates. All rights reserved. This work may not be reproduced or redistributed, in whole or in part, without prior written permission from Amazon Web Services, Inc. Commercial copying, lending, or selling is prohibited. All trademarks are the property of their owners.*\n"]}], "metadata": {"instance_type": "ml.t3.medium", "kernelspec": {"display_name": "conda_python3", "language": "python", "name": "conda_python3"}, "language_info": {"codemirror_mode": {"name": "python", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "pyspark", "pygments_lexer": "python3"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 4}