{"cells": [{"source": ["# Lab 4.1: Implementing Sentiment Analysis\n", " \n", "\n", "\n", "In this lab, you will develop a solution to perform sentiment analysis on the Internet Movie Database (IMDB) dataset.\n", "\n", "## Learning objectives\n", "\n", "- Evaluate machine learning (ML) algorithms that are used in natural language processing (NLP) for sentiment analysis\n", "- Create a solution to a sentiment analysis business problem.\n", "\n", "## Introducing the business scenario\n", "\n", "In this lab, you will play the role of a data scientist on a small development team. The organization that you work for maintains a website of movie reviews. A key customer feature was identified: to provide an overall *Smiley Face* (positive inference) or *Sad Face* (negative inference) for a particular movie based on the number of its positive and negative reviews. You will develop an ML solution that developers can use to create an inference for a movie review. You will need to analyze the review and indicate if it is positive or negative.\n", "\n", "To help with this task, you have access to a dataset that contains the raw text of 50,000 movie reviews. These reviews have been labeled either as positive or negative.\n", "\n", "About this dataset\n", "The Large Movie Review Dataset is a collection of highly polar movie reviews. This data supports work in the following paper:\n", "\n", "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. \"Learning Word Vectors for Sentiment Analysis.\" Presented at the 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011), Portland, Oregon, USA, June 2011. http://ai.stanford.edu/~amaas/data/sentiment/.\n", "\n", "The dataset contains a single text field containing the review. The dataset is labeled either positive (1) or negative (0).\n", "\n", "The dataset contains the following features:\n", "\n", "text: Text of the review\n", "label: Whether the review is positive or negative (1 or 0)\n", "\n", "## Lab steps\n", "\n", "To complete this lab, you will follow these steps:\n", "\n", "1. [Installing packages](#1.-Installing-packages)\n", "2. [Reading the dataset](#2.-Reading-the-dataset)\n", "3. [Performing exploratory data analysis](#3.-Performing-exploratory-data-analysis)\n", "4. [Running the first pass: Minimal processing](#4.-Running-the-first-pass:-Minimal-processing)\n", "5. [Running the second pass: Normalizing the text](#5.-Running-the-second-pass:-Normalizing-the-text)\n", "6. [Tuning hyperparameters](#6.-Tuning-hyperparameters)\n", "7. [Using BlazingText](#7.-Using-BlazingText)\n", "8. [Using-Amazon Comprehend](#8.-Using-Amazon-Comprehend)\n", "\n", "## Submitting your work\n", "\n", "1. In the lab console, choose **Submit** to record your progress and when prompted, choose **Yes**.\n", "\n", "1. If the results don't display after a couple of minutes, return to the top of the lab instructions and choose **Grades**.\n", "\n", "**Tip:** You can submit your work multiple times. After you change your work, choose **Submit** again. Your last submission is what will be recorded for this lab.\n", "\n", "1. To find detailed feedback on your work, choose **Details** followed by **View Submission Report**."], "cell_type": "markdown", "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Installing packages\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "Start by updating and installing the packages that you will use in the notebook. \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Install/Upgrade dependencies\n", "!pip install --upgrade pip\n", "!pip install --upgrade scikit-learn\n", "!pip install --upgrade sagemaker\n", "!pip install --upgrade nltk\n", "!pip install --upgrade seaborn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["__Note:__ Before you proceed with this lab for the first time, we recommend that you restart the kernel by choosing __Kernel__ > __Restart Kernel__."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Import the packages that are used in the notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "import os, io, struct\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from datetime import datetime\n", "\n", "import nltk\n", "nltk.download('punkt')\n", "nltk.download('stopwords')\n", "nltk.download('averaged_perceptron_tagger')\n", "nltk.download('wordnet')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The following code cell includes a few helper functions that  plot a confusion matrix and calculate other key metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "def plot_confusion_matrix(test_labels, target_predicted):\n", "    matrix = confusion_matrix(test_labels, target_predicted)\n", "    df_confusion = pd.DataFrame(matrix)\n", "    colormap = sns.color_palette(\"BrBG\", 10)\n", "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n", "    plt.title(\"Confusion Matrix\")\n", "    plt.tight_layout()\n", "    plt.ylabel(\"True Class\")\n", "    plt.xlabel(\"Predicted Class\")\n", "    plt.show()\n", "    \n", "def print_metrics(test_labels, target_predicted_binary):\n", "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n", "    # Sensitivity, hit rate, recall, or true positive rate\n", "    Sensitivity  = float(TP)/(TP+FN)*100\n", "    # Specificity or true negative rate\n", "    Specificity  = float(TN)/(TN+FP)*100\n", "    # Precision or positive predictive value\n", "    Precision = float(TP)/(TP+FP)*100\n", "    # Negative predictive value\n", "    NPV = float(TN)/(TN+FN)*100\n", "    # Fall out or false positive rate\n", "    FPR = float(FP)/(FP+TN)*100\n", "    # False negative rate\n", "    FNR = float(FN)/(TP+FN)*100\n", "    # False discovery rate\n", "    FDR = float(FP)/(TP+FP)*100\n", "    # Overall accuracy\n", "    ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n", "\n", "    print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n", "    print(f\"Specificity or TNR: {Specificity}%\") \n", "    print(f\"Precision: {Precision}%\")   \n", "    print(f\"Negative Predictive Value: {NPV}%\")  \n", "    print( f\"False Positive Rate: {FPR}%\") \n", "    print(f\"False Negative Rate: {FNR}%\")  \n", "    print(f\"False Discovery Rate: {FDR}%\" )\n", "    print(f\"Accuracy: {ACC}%\") \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Reading the dataset\n", "\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will load the dataset. The dataset has already been downloaded by Amazon Sagemaker Studio. Use the __pandas__ library to read the dataset."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### __Loading the training data:__"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../data/imdb.csv', header=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Performing exploratory data analysis\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will examine the dataset. \n", "\n", "Complete the following functions. The first one has been provided so that you can learn the format.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Listing the first eight rows"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_eight_rows(df):\n", "    # Implement this function\n", "    return df.head(8)    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(show_eight_rows(df))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: What is the shape of the data?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_data_shape(df):\n", "    # Implement this function\n", "    ### BEGIN_SOLUTION\n", "    return df.shape\n", "    ### END_SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(show_data_shape(df))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: How many positive and negative instances are in the data?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_data_instances(df):\n", "    # Implement this function\n", "    ### BEGIN_SOLUTION\n", "    return df['label'].value_counts()\n", "    ### END_SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(show_data_instances(df))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Does the data have any missing values?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_missing_values(df):\n", "    # Implement this function\n", "    ### BEGIN_SOLUTION\n", "    return df.isna().sum()\n", "    ### END_SOLUTION\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(show_missing_values(df))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Running the first pass: Minimal processing\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will perform the minimum steps that are needed to train a classification model. You will use this trained model to see the impact of processing text on the results."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Start by importing the Natural Langauge ToolKit (NLTK) package and the Regular Expression (re) package."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nltk, re\n", "from nltk.corpus import stopwords\n", "from nltk.stem import SnowballStemmer\n", "from nltk.tokenize import word_tokenize"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Splitting the data into datasets for training, validation, and testing\n", "\n", "In this task, you will split the dataset so that you have 80 percent of the dataset for training, and 10 percent each for validation and testing.\n", "\n", "To split the dataset, use the `train_test_split` function from __scikit-learn__. For more information about this function, see the [scikit-learn test_train_split documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) at https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html.\n", "\n", "Specify __df__ as the dataset. Split this dataset into a __train__ set and a __test_and_validate__ set. Then, split the __train_and_validate__ set into the __test__ set and the __validate__ set.\n", "\n", "(*Optional*) For repeatable results, shuffle the deck and **random_state**."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "# uncomment the following lines and implement your solution\n", "def split_data(df):\n", "    # train, test_and_validate = train_test_split(....)\n", "    # test, validate = train_test_split(....)\n", "    ### BEGIN_SOLUTION\n", "    train, test_and_validate = train_test_split(df,\n", "                                            test_size=0.2,\n", "                                            shuffle=True,\n", "                                            random_state=324\n", "                                            )\n", "    test, validate = train_test_split(test_and_validate,\n", "                                                test_size=0.5,\n", "                                                shuffle=True,\n", "                                                random_state=324)\n", "    ### END_SOLUTION\n", "    return train, validate, test"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check whether your datasets are split correctly by running the following code cell."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train, validate, test = split_data(df)\n", "print(train.shape)\n", "print(test.shape)\n", "print(validate.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Assembling the processing pipeline\n", "\n", "In this cell, the basic processing pipeline is assembled for the text data. You will now modify this implementation to add more features."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.compose import ColumnTransformer\n", "\n", "text_features = ['text']\n", "model_target = 'label'\n", "\n", "text_processor_0 = Pipeline([\n", "    ('text_vect_0', CountVectorizer(max_features=500))\n", "])\n", "\n", "data_preprocessor = ColumnTransformer([\n", "    ('text_pre_0', text_processor_0, text_features[0])\n", "])\n", "\n", "print('Datasets shapes before processing: ', train.shape, validate.shape, test.shape)\n", "train_matrix = data_preprocessor.fit_transform(train)\n", "test_matrix = data_preprocessor.transform(test)\n", "validate_matrix = data_preprocessor.transform(validate)\n", "print('Datasets shapes after processing: ', train_matrix.shape, validate_matrix.shape, test_matrix.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To train a model, the data must be uploaded to Amazon Simple Storage Service (Amazon S3) in the correct format. XGBoost uses a comma-separated values (CSV) file."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["s3_resource = boto3.Session().resource('s3')\n", "\n", "def upload_s3_csv(filename, folder, X_train, y_train, is_test=False):\n", "    csv_buffer = io.StringIO()\n", "    features = [t.toarray().astype('float32').flatten().tolist() for t in X_train]\n", "    if is_test:\n", "        temp_list = features\n", "    else:\n", "        temp_list = np.insert(features, 0, y_train['label'], axis=1)\n", "    np.savetxt(csv_buffer, temp_list, delimiter=',' )\n", "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bucket = 'c51302a798363l1767466t1w753256443787-labbucket-vzr6xg8irt81'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set the file names for this pass."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prefix='lab41'\n", "train_file='train-pass1.csv'\n", "validate_file='validate-pass1.csv'\n", "test_file='test-pass1.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Upload the train, validate, and test datasets to Amazon S3."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["upload_s3_csv(train_file, 'train', train_matrix, train)\n", "upload_s3_csv(validate_file, 'validate', validate_matrix, validate)\n", "upload_s3_csv(test_file, 'test', test_matrix, test, True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Training an XGBoost model\n", "\n", "Uncomment and complete the following SageMaker function to create an `Estimator`. Use the following parameters:\n", "- **role**: Use the current SageMaker role (__Hint:__ Use `sagemaker.get_execution_role()`)\n", "- **instance count**: `1`\n", "- **instance type**: `ml.m5.xlarge`\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sagemaker\n", "from sagemaker.image_uris import retrieve\n", "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n", "s3_output_location=f's3://{bucket}/{prefix}/output/'\n", "\n", "hyperparams={\"num_round\":\"42\",\n", "             \"eval_metric\": \"error\",\n", "             \"objective\": \"binary:logistic\",\n", "             \"silent\" : 1}\n", "\n", "# xgb_model=sagemaker.estimator.Estimator(container,\n", "#                                         role=<INSERT_ROLE_HERE>,\n", "#                                         instance_count=<INSERT_COUNT_HERE>,\n", "#                                         instance_type=<INSERT_INSTANCE_TYPE_HERE>,\n", "#                                         output_path=s3_output_location,\n", "#                                         hyperparameters=hyperparams,\n", "#                                         sagemaker_session=sagemaker.Session())\n", "### BEGIN_SOLUTION\n", "xgb_model=sagemaker.estimator.Estimator(container,\n", "                                        role=sagemaker.get_execution_role(),\n", "                                        instance_count=1,\n", "                                        instance_type='ml.m5.2xlarge',\n", "                                        output_path=s3_output_location,\n", "                                        hyperparameters=hyperparams,\n", "                                        sagemaker_session=sagemaker.Session())\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set up the two data channels. One data channel is for the training data that's used to train the model. The second data channel is for the validation data that's used to generate performance metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_channel = sagemaker.inputs.TrainingInput(\n", "    f's3://{bucket}/{prefix}/train/{train_file}',\n", "    content_type='text/csv')\n", "\n", "validate_channel = sagemaker.inputs.TrainingInput(\n", "    f's3://{bucket}/{prefix}/validate/{validate_file}',\n", "    content_type='text/csv')\n", "\n", "data_channels = {'train': train_channel, 'validation': validate_channel}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the model. (This step might take a few minutes.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "xgb_model.fit(inputs=data_channels, logs=False, job_name='xgb-pass1-'+datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\"))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display the metrics from the current XGBoost job."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n", "                                         metric_names = ['train:error','validation:error']\n", "                                        ).dataframe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The initial results don't seem to be useful. Use the __test__ dataset to calculate more metrics. (This step might take a few minutes.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "upload_s3_csv('batch-in.csv', 'batch-in', test_matrix, test, True)\n", "batch_X_file='batch-in.csv'\n", "batch_output = f's3://{bucket}/{prefix}/batch-out/'\n", "batch_input = f's3://{bucket}/{prefix}/batch-in/{batch_X_file}'\n", "\n", "xgb_transformer = xgb_model.transformer(instance_count=1,\n", "                                       instance_type='ml.m5.2xlarge',\n", "                                       strategy='MultiRecord',\n", "                                       assemble_with='Line',\n", "                                       output_path=batch_output)\n", "\n", "xgb_transformer.transform(data=batch_input,\n", "                         data_type='S3Prefix',\n", "                         content_type='text/csv',\n", "                         split_type='Line',\n", "                         job_name='xgboost-pass1')\n", "xgb_transformer.wait(logs=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["s3 = boto3.client('s3')\n", "obj = s3.get_object(Bucket=bucket, Key=f'{prefix}/batch-out/batch-in.csv.out')\n", "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),',',names=['class'])\n", "\n", "def binary_convert(x):\n", "    threshold = 0.5\n", "    if x > threshold:\n", "        return 1\n", "    else:\n", "        return 0\n", "\n", "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_confusion_matrix(test['label'], target_predicted_binary)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_metrics(test['label'], target_predicted_binary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Second pass: Normalizing the text\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will perform some standard preprocessing tasks on the text before you retrain the model."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Removing stopwords that might impact sentiment\n", "\n", "You could remove all the stopwords, but you might want to keep the stopwords that could impact the sentiment, such as __not__ or __don't__. \n", "\n", "A few stopwords to exclude have been provided. Update the function to remove other words that might impact sentiment."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get a list of stopwords from the NLTK library\n", "stop = stopwords.words('english')\n", "\n", "def remove_stopwords(stopwords):\n", "    # Implement this function\n", "    excluding = ['against', 'not', 'don', 'don\\'t','ain', 'are', 'aren\\'t']\n", "    ### BEGIN_SOLUTION\n", "    excluding = ['against', 'not', 'don', 'don\\'t','ain', 'are', 'aren\\'t', 'could', 'couldn\\'t',\n", "             'did', 'didn\\'t', 'does', 'doesn\\'t', 'had', 'hadn\\'t', 'has', 'hasn\\'t', \n", "             'have', 'haven\\'t', 'is', 'isn\\'t', 'might', 'mightn\\'t', 'must', 'mustn\\'t',\n", "             'need', 'needn\\'t','should', 'shouldn\\'t', 'was', 'wasn\\'t', 'were', \n", "             'weren\\'t', 'won\\'t', 'would', 'wouldn\\'t']\n", "    ### END_SOLUTION\n", "    return [word for word in stop if word not in excluding]\n", "\n", "# New stopword list\n", "stopwords = remove_stopwords(stop)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Adding cleanup steps\n", "\n", "Update the following `clean` function to complete the following tasks:\n", "- Remove leading spaces and trailing spaces\n", "- Remove any HTML tags\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["snow = SnowballStemmer('english')\n", "def clean(sent):\n", "    # Implement this function\n", "    sent = sent.lower()\n", "    sent = re.sub('\\s+', ' ', sent)\n", "    ### BEGIN_SOLUTION\n", "    sent = sent.strip()\n", "    sent = re.compile('<.*?>').sub('',sent)\n", "    ### END_SOLUTION\n", "    filtered_sentence = []\n", "    \n", "    for w in word_tokenize(sent):\n", "        # You are applying custom filtering here. Feel free to try different things.\n", "        # Check if it is not numeric, its length > 2, and it is not in stopwords\n", "        if(not w.isnumeric()) and (len(w)>2) and (w not in stopwords):  \n", "            # Stem and add to filtered list\n", "            filtered_sentence.append(snow.stem(w))\n", "    final_string = \" \".join(filtered_sentence) #final string of cleaned words\n", "    return final_string"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create new test, validate, and test dataframes by using the function that you created earlier."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Uncomment the next line and implement the function call to split_data\n", "#train, validate, test = \n", "\n", "### BEGIN_SOLUTION\n", "train, validate, test = split_data(df)\n", "### END_SOLUTION\n", "\n", "print(train.shape)\n", "print(test.shape)\n", "print(validate.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The pipeline has been updated to include a call to the previously defined `clean` function from the `CountVectorizer`. This function will take a little longer to run."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.compose import ColumnTransformer\n", "\n", "text_features = ['text']\n", "model_target = 'label'\n", "\n", "text_processor_0 = Pipeline([\n", "    ('text_vect_0', CountVectorizer(preprocessor=clean, max_features=500))\n", "])\n", "\n", "data_preprocessor = ColumnTransformer([\n", "    ('text_pre_0', text_processor_0, text_features[0])\n", "])\n", "\n", "print('Datasets shapes before processing: ', train.shape, validate.shape, test.shape)\n", "train_matrix = data_preprocessor.fit_transform(train)\n", "test_matrix = data_preprocessor.transform(test)\n", "validate_matrix = data_preprocessor.transform(validate)\n", "print('Datasets shapes after processing: ', train_matrix.shape, validate_matrix.shape, test_matrix.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set the file names for this pass."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prefix='lab41'\n", "train_file='train_pass2.csv'\n", "validate_file='validate_pass2.csv'\n", "test_file='test_pass2.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Uploading the files to Amazon S3\n", "\n", "Use the previous code to upload the new files to Amazon S3. \n", "\n", "__Tip:__ Copy the code and paste it into the following code cell."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### BEGIN_SOLUTION\n", "upload_s3_csv(train_file, 'train', train_matrix, train)\n", "upload_s3_csv(validate_file, 'validate', validate_matrix, validate)\n", "upload_s3_csv(test_file, 'test', test_matrix, test, True)\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Creating the estimator and setting up the data channels\n", "\n", "Use the previous code to set up the estimator and data channels. \n", "\n", "__Tip:__ Copy the code from the previous cell and paste it into the following cell."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n", "\n", "hyperparams={\"num_round\":\"42\",\n", "             \"eval_metric\": \"error\",\n", "             \"objective\": \"binary:logistic\",\n", "             \"silent\" : 1}\n", "\n", "### BEGIN_SOLUTION\n", "xgb_model=sagemaker.estimator.Estimator(container,\n", "                                        sagemaker.get_execution_role(),\n", "                                        instance_count=1,\n", "                                        instance_type='ml.m5.2xlarge',\n", "                                        output_path=s3_output_location,\n", "                                        hyperparameters = hyperparams,\n", "                                        sagemaker_session=sagemaker.Session())\n", "\n", "train_channel = sagemaker.inputs.TrainingInput(\n", "    f's3://{bucket}/{prefix}/train/{train_file}',\n", "    content_type='text/csv')\n", "\n", "validate_channel = sagemaker.inputs.TrainingInput(\n", "    f's3://{bucket}/{prefix}/validate/{validate_file}',\n", "    content_type='text/csv')\n", "\n", "data_channels = {'train': train_channel, 'validation': validate_channel}\n", "\n", "### END_SOLUTION\n", "\n", "xgb_model.fit(inputs=data_channels, logs=False, job_name='xgb-pass2-'+datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n", "                                         metric_names = ['train:error','validation:error']\n", "                                        ).dataframe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Creating a batch transformer job\n", "\n", "Using the previous code, create a transformer job. (This step might take a few minutes to complete.) \n", "\n", "__Tip:__ Copy the code from the previous example and paste it into the following cell."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "### BEGIN_SOLUTION\n", "xgb_transformer = xgb_model.transformer(instance_count=1,\n", "                                       instance_type='ml.m5.2xlarge',\n", "                                       strategy='MultiRecord',\n", "                                       assemble_with='Line',\n", "                                       output_path=batch_output)\n", "\n", "xgb_transformer.transform(data=batch_input,\n", "                         data_type='S3Prefix',\n", "                         content_type='text/csv',\n", "                         split_type='Line')\n", "### END_SOLUTION\n", "\n", "xgb_transformer.wait(logs=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["s3 = boto3.client('s3')\n", "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n", "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),',',names=['class'])\n", "\n", "def binary_convert(x):\n", "    threshold = 0.5\n", "    if x > threshold:\n", "        return 1\n", "    else:\n", "        return 0\n", "\n", "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_confusion_matrix(test['label'], target_predicted_binary)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_metrics(test['label'], target_predicted_binary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Is the new model better or worse than the first model?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Tuning hyperparameters\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will create a hyperparameter tuning job to tune the model.\n", "\n", "__Note__: Tuning Hyperparameters takes about an hour to complete. If you don't have enough time, proceed to Section 7. You can also skip to section 7 after you start the tuning job, and return to its results later."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Creating the estimator to tune\n", "\n", "The first step is to create an estimator to tune. Uncomment and complete the following estimator code:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# xgb = sagemaker.estimator.Estimator(....)\n", "### BEGIN_SOLUTION\n", "xgb = sagemaker.estimator.Estimator(container,\n", "                                    role=sagemaker.get_execution_role(), \n", "                                    instance_count= 1, # make sure you have limit set for these instances\n", "                                    instance_type='ml.m5.2xlarge', \n", "                                    output_path=f's3://{bucket}/{prefix}/output',\n", "                                    sagemaker_session=sagemaker.Session())\n", "### END_SOLUTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xgb.set_hyperparameters(eval_metric='error',\n", "                        objective='binary:logistic',\n", "                        num_round=42,\n", "                        silent=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Creating the hyperparameter ranges\n", "\n", "Using the [XGBoost Tuning documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html), add hyperparameter ranges to the following cell.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n", "\n", "hyperparameter_ranges = {'alpha': ContinuousParameter(0,1000)}\n", "\n", "### BEGIN_SOLUTION\n", "hyperparameter_ranges = {'alpha': ContinuousParameter(0, 1000),\n", "                         'min_child_weight': ContinuousParameter(0, 120),\n", "                         'subsample': ContinuousParameter(0.5, 1),\n", "                         'eta': ContinuousParameter(0.1, 0.5),  \n", "                         'num_round': IntegerParameter(1,4000)\n", "                         }\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Specifying the target metrics\n", "\n", "Update the `objective_metric_name` and `objective_type` to appropriate values for a binary classification problem. For more information, see the [XGBoost Tuning documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["objective_metric_name = '<INSERT_VALUE_HERE>'\n", "objective_type = '<INSERT_VALUE_HERE>'\n", "\n", "### BEGIN_SOLUTION\n", "objective_metric_name = 'validation:error'\n", "objective_type = 'Minimize'\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the hyperparameter tuning job."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tuner = HyperparameterTuner(xgb,\n", "                            objective_metric_name,\n", "                            hyperparameter_ranges,\n", "                            max_jobs=10, # Set this to 10 or above depending upon budget & available time.\n", "                            max_parallel_jobs=1,\n", "                            objective_type=objective_type,\n", "                            early_stopping_type='Auto',\n", "                           )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Run the tuning job. Note that this job might take around 60 minutes to complete. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "tuner.fit(inputs=data_channels, include_cls_metadata=False, wait=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you want to try Section 7 while you wait, don't run the next cell and go to Section 7."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tuner.wait()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When the tuning job is complete, you can view the metrics from the tuning jobs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pprint import pprint\n", "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n", "\n", "tuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n", "\n", "df_tuning_job_analytics = tuner_analytics.dataframe()\n", "\n", "# Sort the tuning job analytics by the final metrics value\n", "df_tuning_job_analytics.sort_values(\n", "    by=['FinalObjectiveValue'],\n", "    inplace=True,\n", "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n", "\n", "# Show detailed analytics for the top 20 models\n", "df_tuning_job_analytics.head(20)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Using the best hyperparameter job\n", "\n", "After the tuning job is complete, you can find the best tuning job from the **HyperparameterTuner** object.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n", "best_training_job = attached_tuner.best_training_job()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sagemaker.estimator import Estimator\n", "algo_estimator = Estimator.attach(best_training_job)\n", "\n", "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Run the test data through the data processing pipeline so that you can test the model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.compose import ColumnTransformer\n", "\n", "text_features = ['text']\n", "model_target = 'label'\n", "\n", "text_processor_0 = Pipeline([\n", "    ('text_vect_0', CountVectorizer(preprocessor=clean, max_features=500))\n", "])\n", "\n", "data_preprocessor = ColumnTransformer([\n", "    ('text_pre_0', text_processor_0, text_features[0])\n", "])\n", "\n", "print('Datasets shapes before processing: ', train.shape, validate.shape, test.shape)\n", "train_matrix = data_preprocessor.fit_transform(train)\n", "test_matrix = data_preprocessor.transform(test)\n", "validate_matrix = data_preprocessor.transform(validate)\n", "print('Datasets shapes after processing: ', train_matrix.shape, validate_matrix.shape, test_matrix.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use the test data on a batch transformation by using the best algorithm from the hyperparameter tuning job."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "upload_s3_csv('batch-in.csv', 'batch-in', test_matrix, test, True)\n", "\n", "batch_output = f's3://{bucket}/{prefix}/batch-out/'\n", "batch_input = f's3://{bucket}/{prefix}/batch-in/{batch_X_file}'\n", "\n", "xgb_transformer = best_algo_model.transformer(instance_count=1,\n", "                                       instance_type='ml.m5.2xlarge',\n", "                                       strategy='MultiRecord',\n", "                                       assemble_with='Line',\n", "                                       output_path=batch_output)\n", "xgb_transformer.transform(data=batch_input,\n", "                         data_type='S3Prefix',\n", "                         content_type='text/csv',\n", "                         split_type='Line')\n", "xgb_transformer.wait(logs=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Process the results to calculate the class."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["s3 = boto3.client('s3')\n", "obj = s3.get_object(Bucket=bucket, Key=f'{prefix}/batch-out/batch-in.csv.out')\n", "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),',',names=['class'])\n", "\n", "def binary_convert(x):\n", "    threshold = 0.5\n", "    if x > threshold:\n", "        return 1\n", "    else:\n", "        return 0\n", "\n", "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the confusion matrix and print the metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_confusion_matrix(test['label'], target_predicted_binary)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_metrics(test['label'], target_predicted_binary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Using BlazingText\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will use BlazingText, which is a built-in Amazon SageMaker algorithm. BlazingText can perform classification without modifications. You will reformat the data for BlazingText. You will then use the data to train the algorithm and compare the results to the previous models.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Start by obtaining the container for the algorithm."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sagemaker\n", "from sagemaker.image_uris import retrieve\n", "\n", "container = retrieve('blazingtext',boto3.Session().region_name,\"latest\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Configure the prefixes for the training, validation, and test data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import io\n", "    \n", "prefix='lab41'\n", "train_file='blazing_train.txt'\n", "validate_file='blazing_validate.txt'\n", "test_file='blazing_test.txt'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Remind yourself of what the data looks like."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "BlazingText needs the data in the following format:\n", "\n", "\\__label__1 Caught this movie on the tube on a Sunday...\n", "\n", "The following two cells convert the dataframes into the correct format, and upload them to Amazon S3."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["blazing_text_buffer = io.StringIO()\n", "train.to_string(buf=blazing_text_buffer, columns=['label','text'], header=False, index=False, formatters=\n", "                         {'label': '__label__{}'.format})\n", "s3r = boto3.resource('s3')\n", "s3r.Bucket(bucket).Object(os.path.join(prefix, 'blazing', train_file)).put(Body=blazing_text_buffer.getvalue())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["blazing_text_buffer = io.StringIO()\n", "validate.to_string(buf=blazing_text_buffer, columns=['label','text'], header=False, index=False, formatters=\n", "                         {'label': '__label__{}'.format})\n", "s3r.Bucket(bucket).Object(os.path.join(prefix, 'blazing', validate_file)).put(Body=blazing_text_buffer.getvalue())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Training the BlazingText estimator\n", "\n", "In the next cell, uncomment and complete the estimator code by specifying the missing values. \n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# bt_model = sagemaker.estimator.Estimator(container,\n", "#                                         sagemaker.get_execution_role(), \n", "#                                         instance_count=, \n", "#                                         instance_type=,\n", "#                                         volume_size = 30,\n", "#                                         max_run = 360000,\n", "#                                         input_mode= 'File',\n", "#                                         output_path=,\n", "#                                         sagemaker_session=\n", "\n", "### BEGIN_SOLUTION\n", "bt_model = sagemaker.estimator.Estimator(container,\n", "                                         sagemaker.get_execution_role(), \n", "                                         instance_count=1, \n", "                                         instance_type='ml.c4.4xlarge',\n", "                                         volume_size = 30,\n", "                                         max_run = 360000,\n", "                                         input_mode= 'File',\n", "                                         output_path=s3_output_location,\n", "                                         sagemaker_session=sagemaker.Session())\n", "\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use the following hyperparameters:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bt_model.set_hyperparameters(mode=\"supervised\",\n", "                            epochs=10,\n", "                            min_count=2,\n", "                            learning_rate=0.05,\n", "                            vector_dim=10,\n", "                            early_stopping=True,\n", "                            patience=4,\n", "                            min_epochs=5,\n", "                            word_ngrams=2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set up the training channel and the validate channel."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_channel = sagemaker.inputs.TrainingInput(\n", "    f's3://{bucket}/{prefix}/blazing/{train_file}',\n", "    content_type='text/csv')\n", "\n", "validate_channel = sagemaker.inputs.TrainingInput(\n", "    f's3://{bucket}/{prefix}/blazing/{validate_file}',\n", "    content_type='text/csv')\n", "\n", "data_channels_3 = {'train': train_channel, 'validation': validate_channel}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Starting the training job\n", "\n", "Start the training job by entering the following code. (This step might take a few minutes.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "### BEGIN_SOLUTION\n", "bt_model.fit(inputs=data_channels_3, logs=False)\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After the training job is complete, view the training metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sagemaker.analytics.TrainingJobAnalytics(bt_model._current_job_name, \n", "                                         metric_names = ['train:accuracy','validation:accuracy']\n", "                                        ).dataframe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pd.options.display.max_rows\n", "pd.set_option('display.max_colwidth', None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Make a copy of the test data so that it can be formatted to use the model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bt_test = test.copy()\n", "bt_test.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Format the dataset into the format that BlazingText needs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# bt_test['text'].str.strip()\n", "bt_test.replace(r'\\\\n','', regex=True, inplace = True)\n", "bt_test.rename(columns={'text':'source'}, inplace=True)\n", "bt_test.drop(columns='label', inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(bt_test.head().to_json(orient=\"records\", lines=True))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Upload the file to Amazon S3."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bt_file = 'bt_input.json'\n", "blazing_text_buffer = io.StringIO()\n", "bt_test.to_json(path_or_buf=blazing_text_buffer, orient=\"records\", lines=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["s3r.Bucket(bucket).Object(os.path.join(prefix, 'blazing', bt_file)).put(Body=blazing_text_buffer.getvalue())\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["batch_output = f's3://{bucket}/{prefix}/blazing/'\n", "batch_input = f's3://{bucket}/{prefix}/blazing/{bt_file}'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use a batch transformer on the test data. (This step might take a few minutes.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "bt_transformer = bt_model.transformer(instance_count=1,\n", "                                       instance_type='ml.m5.2xlarge',\n", "                                       strategy='MultiRecord',\n", "                                       assemble_with='Line',\n", "                                       output_path=batch_output)\n", "\n", "bt_transformer.transform(data=batch_input,\n", "                         data_type='S3Prefix',\n", "                         content_type='application/jsonlines',\n", "                         split_type='Line')\n", "\n", "bt_transformer.wait(logs=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Retrieve the results from Amazon S3."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["obj = s3.get_object(Bucket=bucket, Key=f'{prefix}/blazing/bt_input.json.out')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target_predicted = pd.read_json(io.BytesIO(obj['Body'].read()),lines=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target_predicted.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Reformat the results so that you can calculate the confusion matrix and the metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def binary_convert(label):\n", "    label = label[0].replace('__label__','')\n", "    return int(label)\n", "\n", "target_predicted_binary = target_predicted['label'].apply(binary_convert)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_confusion_matrix(test['label'], target_predicted_binary)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_metrics(test['label'], target_predicted_binary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["How did BlazingText perform compared to the previous models?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Using Amazon Comprehend\n", "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n", "\n", "In this section, you will use Amazon Comprehend to calculate the sentiment. Amazon Comprehend gives you positive and negative results, and it also shows neutral and mixed results. Amazon Comprehend is a managed service, and it requires less text processing before it's used. You won't need to process any text in this section."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Review what the data looks like in the `test` dataframe."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using Amazon Comprehend can be as straightforward as making an API call.\n", "\n", "The following cell outputs the first five results from Amazon Comprehend."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "import json\n", "\n", "comprehend = boto3.client(service_name='comprehend')\n", "for n in range(5):\n", "    text = test.iloc[n]['text']\n", "    response = comprehend.detect_sentiment(Text=text, LanguageCode='en')\n", "    sentiment = response['Sentiment']\n", "    print(f'{sentiment} - {text}')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can start a prediction job to process multiple items. The input must be formatted as a single input per line, and uploaded to Amazon S3. The text has a maximum size of 5120, so the `str.slice(0,5000)` function is used to trim long text."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Upload test file minus label to S3\n", "def upload_comprehend_s3_csv(filename, folder, dataframe):\n", "    csv_buffer = io.StringIO()\n", "    \n", "    dataframe.to_csv(csv_buffer, header=False, index=False )\n", "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n", "\n", "comprehend_file = 'comprehend_input.csv'\n", "upload_comprehend_s3_csv(comprehend_file, 'comprehend', test['text'].str.slice(0,5000))\n", "test_url = f's3://{bucket}/{prefix}/comprehend/{comprehend_file}'\n", "print(f'Uploaded input to {test_url}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When the data is uploaded to Amazon S3, you start the job by using the `start_sentiment_detection_jon` function. \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Challenge: Configuring the Amazon Comprehend job parameters\n", "\n", "In the next cell, configure the Amazon Comprehend job parameters. \n", "- In __input_data_config__ - \n", "  - **S3Uri**: Replace *`<S3_INPUT_GOES_HERE>`* with the `test_uri` that was defined previously\n", "  - **InputFormat**: Replace *`<INPUT_FORMAT_GOES_HERE>`* with `ONE_DOC_PER_LINE`\n", "- In __output_data-config__ -  \n", "  - **S3Uri**: Replace *`<S3_OUTPUT_GOES_HERE>`*  with the `s3_output_location`\n", "  - **data_access_role_arn**: Replace *`arn:aws:iam::753256443787:role/service-role/c51302a798363l1767466t1w7-ComprehendDataAccessRole-396LD2R02VHP`* with the Amazon Resource Name (ARN) from the *Lab Details* file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_data_config={\n", "    'S3Uri': 'S3_INPUT_GOES_HERE',\n", "    'InputFormat': 'INPUT_FORMAT_GOES_HERE'\n", "},\n", "\n", "output_data_config={\n", "    'S3Uri': 'S3_OUTPUT_GOES_HERE'\n", "},\n", "data_access_role_arn = 'arn:aws:iam::753256443787:role/service-role/c51302a798363l1767466t1w7-ComprehendDataAccessRole-396LD2R02VHP'\n", "\n", "### BEGIN_SOLUTION\n", "input_data_config={\n", "    'S3Uri': test_url,\n", "    'InputFormat': 'ONE_DOC_PER_LINE'\n", "}\n", "output_data_config={\n", "    'S3Uri': s3_output_location\n", "}\n", "data_access_role_arn = 'arn:aws:iam::753256443787:role/service-role/c51302a798363l1767466t1w7-ComprehendDataAccessRole-396LD2R02VHP'\n", "### END_SOLUTION"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now that you defined the job parameters, start the sentiment detection job."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["response = comprehend.start_sentiment_detection_job(\n", "    InputDataConfig=input_data_config,\n", "    OutputDataConfig=output_data_config,\n", "    DataAccessRoleArn=data_access_role_arn,\n", "    JobName='movie_sentiment',\n", "    LanguageCode='en'\n", ")\n", "\n", "print(response['JobStatus'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The following cell will loop until the job is completed. (This step might take a few minutes to complete.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "import time\n", "job_id = response['JobId']\n", "while True:\n", "    job_status=(comprehend.describe_sentiment_detection_job(JobId=job_id))\n", "    if job_status['SentimentDetectionJobProperties']['JobStatus'] in ['COMPLETED','FAILED']:\n", "        break            \n", "    else:\n", "        print('.', end='')\n", "    time.sleep(15)\n", "print((comprehend.describe_sentiment_detection_job(JobId=job_id))['SentimentDetectionJobProperties']['JobStatus'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When the job is complete, you can return the details from the job by calling the `describe_sentiment_detection_job` function."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output=(comprehend.describe_sentiment_detection_job(JobId=job_id))\n", "print(output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the **OutputDataConfig** section, you should see the `S3Uri`. Extracting that URI will give you the file that you must download from Amazon S3. You can use the results to calculate metrics in the same way that you calculated the results from a batch transformation by using an algorithm."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["comprehend_output_file = output['SentimentDetectionJobProperties']['OutputDataConfig']['S3Uri']\n", "comprehend_bucket, comprehend_key = comprehend_output_file.replace(\"s3://\", \"\").split(\"/\", 1)\n", "\n", "s3r = boto3.resource('s3')\n", "s3r.meta.client.download_file(comprehend_bucket, comprehend_key, 'output.tar.gz')\n", "\n", "# Extract the tar file\n", "import tarfile\n", "tf = tarfile.open('output.tar.gz')\n", "tf.extractall()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The extracted file should be named __output__. Read the the lines in this file."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "data = ''\n", "with open ('output', \"r\") as myfile:\n", "    data = myfile.readlines()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add the lines to an array."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = []\n", "for line in data:\n", "    json_data = json.loads(line)\n", "    results.append([json_data['Line'],json_data['Sentiment']])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert the array to a pandas dataframe. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["c = pd.DataFrame.from_records(results, index='index', columns=['index','sentiment'])\n", "c.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The results contain **NEGATIVE**, **POSITIVE**, **NEUTRAL**, and **MIXED** results instead of numerical values. To compare these results to your test data, they can be mapped to numerical values, as shown in the following cell. The index in the returned results is also out of order. The `sort_index` function should fix this issue."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_mapper = {'NEGATIVE':0, 'POSITIVE':1, 'NEUTRAL':2, 'MIXED':3}\n", "c['sentiment']=c['sentiment'].replace(class_mapper)\n", "c = c.sort_index()\n", "c.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Build list to compare for Amazon Comprehend\n", "test_2 = test.reset_index()\n", "test_3 = test_2.sort_index()\n", "test_labels = test_3.iloc[:,2]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can display a confusion matrix by using the `plot_confusion_matrix` function. Because Amazon Comprehend also includes __mixed__ and __neutral__ in the results, the chart will be different."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_confusion_matrix(test_labels, c['sentiment'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The existing function to print metrics won't work because you have too many data dimensions. The following code cell will calculate the same values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(test_labels, c['sentiment'])\n", "\n", "TN = cm[0,0]\n", "FP = cm[0,1]\n", "FN = cm[1,0]\n", "TP = cm[1,1]\n", "\n", "Sensitivity  = float(TP)/(TP+FN)*100\n", "# Specificity or true negative rate\n", "Specificity  = float(TN)/(TN+FP)*100\n", "# Precision or positive predictive value\n", "Precision = float(TP)/(TP+FP)*100\n", "# Negative predictive value\n", "NPV = float(TN)/(TN+FN)*100\n", "# Fall out or false positive rate\n", "FPR = float(FP)/(FP+TN)*100\n", "# False negative rate\n", "FNR = float(FN)/(TP+FN)*100\n", "# False discovery rate\n", "FDR = float(FP)/(TP+FP)*100\n", "# Overall accuracy\n", "ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n", "\n", "print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n", "print(f\"Specificity or TNR: {Specificity}%\") \n", "print(f\"Precision: {Precision}%\")   \n", "print(f\"Negative Predictive Value: {NPV}%\")  \n", "print( f\"False Positive Rate: {FPR}%\") \n", "print(f\"False Negative Rate: {FNR}%\")  \n", "print(f\"False Discovery Rate: {FDR}%\" )\n", "print(f\"Accuracy: {ACC}%\") "]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Congratulations!\n", "\n", "You have completed this lab, and you can now end the lab by following the lab guide instructions."]}, {"source": ["*\u00a92021 Amazon Web Services, Inc. or its affiliates. All rights reserved. This work may not be reproduced or redistributed, in whole or in part, without prior written permission from Amazon Web Services, Inc. Commercial copying, lending, or selling is prohibited. All trademarks are the property of their owners.*\n"], "cell_type": "markdown", "metadata": {}}], "metadata": {"instance_type": "ml.t3.medium", "kernelspec": {"display_name": "conda_python3", "language": "python", "name": "conda_python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}, "metadata": {"interpreter": {"hash": "12bdb53ebf8de4a8c3e84b62f6391946884c7c7585d9344b706f290a85145ccc"}}}, "nbformat": 4, "nbformat_minor": 4}